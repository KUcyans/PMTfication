import pyarrow.parquet as pq
import pyarrow as pa
import pyarrow.csv as pcsv
import os

from EventFilter import EventFilter, override
'''
What are CR Cleaned a.k.a Pure Neutrino events?

The event data comes form digitalised signals from PMTs which means that the photoelectrons are the origin of the data.
However, the photoelectrons can be generated by cosmic rays, neutrinos, or other sources.

According to Janni's analysis, more than 67% of the events have a non-neutrino-to-total photoelectron ratio greater than 0.9.
meaning that a large proportion of detected signals likely originate from non-neutrino sources. 
He generated lists of event numbers containing events with non-neutrino-to-total photoelectron ratio less than 0.9.

The purpose of this filter is to remove all events that are not generated by neutrinos.
The events that are generated by neutrinos are called "pure neutrino events".

`_get_event_specifier_files` contains very specific path to the directory where the pure neutrino events are stored.
'''
class PureNeutrinoEventFilter(EventFilter):
    def __init__(self, 
                 source_subdir: str, 
                 output_subdir: str, 
                 subdir_no: int, 
                 part_no: int):
        self.pure_nu_specifier_dir = "/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/clean_events_dict/"
        super().__init__(source_subdir=source_subdir,
                        output_subdir=output_subdir,
                        subdir_no=subdir_no,
                        part_no=part_no)

    @override
    def _set_valid_event_nos(self):
        truth_table = pq.read_table(self.source_truth_file)
        relevant_csvs = self._get_relevant_csv_files(truth_table)
        if not relevant_csvs:
            self.logger.warning(f"No matching CSV files found for {self.subdir_no}/{self.part_no}")

        pure_neutrino_events = self._load_pure_neutrino_events(relevant_csvs)
        required_columns = {"RunID", "EventID", "N_doms"}
        missing_columns = required_columns - set(truth_table.column_names)
        if missing_columns:
            self.logger.error(f"Missing required columns: {missing_columns}. Cannot proceed with filtering.")
            return None
        run_ids = truth_table.column("RunID").to_pylist()
        event_ids = truth_table.column("EventID").to_pylist()

        valid_indices = [i for i, (rid, eid) in enumerate(zip(run_ids, event_ids)) if (rid, eid) in pure_neutrino_events]

        if not valid_indices:
            self.logger.warning(f"No valid events in {self.subdir_no}/{self.part_no}. Skipping filtering.")
            return None

        filtered_table = truth_table.take(valid_indices)
        self.valid_event_nos = set(filtered_table.column("event_no").to_pylist())
        self.logger.info(f"Extracted {len(self.valid_event_nos)} valid events based on pure neutrino events.")
    
    def _get_relevant_csv_files(self, truth_table: pa.Table) -> list:
        file_ranges = self._get_event_specifier_files()
        
        run_ids = truth_table.column("RunID").to_pylist()
        effective_run_ids = [rid % 100000 for rid in run_ids]

        min_id, max_id = min(effective_run_ids), max(effective_run_ids)
        relevant_files = [file for file_min, file_max, file in file_ranges if file_min <= max_id and file_max >= min_id]

        self.logger.info(f"Selected {len(relevant_files)} CSV files covering event range [{min_id}, {max_id}]")
        return relevant_files

    def _get_event_specifier_files(self) -> list:
        """Loads Janni files from the specified directory."""
        ### HACK the path can extremely specific
        csv_path = os.path.join(self.pure_nu_specifier_dir, str(self.subdir_no), str(self.subdir_no), 'reduced')
        files = os.listdir(csv_path)

        file_ranges = [
            (int(f.split("_")[-1].split("-")[0]), int(f.split("-")[-1].split(".")[0]), os.path.join(csv_path, f))
            for f in files if f.startswith("clean_event_ids_") and f.endswith(".csv")
        ]

        file_ranges.sort(key=lambda x: x[0])
        self.logger.info(f"Loaded {len(file_ranges)} event specifier files from {csv_path}")
        return file_ranges

    def _load_pure_neutrino_events(self, csv_files: list) -> set:
        """Loads (RunID, EventID) pairs from relevant CSV files."""
        pure_neutrino_events = set()
        for csv_file in csv_files:
            table = pcsv.read_csv(csv_file)
            run_ids = table.column("RunID").to_pylist()
            event_ids = table.column("EventID").to_pylist()
            pure_neutrino_events.update(zip(run_ids, event_ids))

        self.logger.info(f"Loaded {len(pure_neutrino_events)} valid (RunID, EventID) pairs from CSV files")
        return pure_neutrino_events