{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.csv as pc\n",
    "import pyarrow.parquet as pq\n",
    "from abc import ABC, abstractmethod\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMTfied_dir = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/PMTfied/\"\n",
    "truth_18_1 = PMTfied_dir + \"Snowstorm/22018/truth_1.parquet\"\n",
    "pmtfied_18_1_1 = PMTfied_dir + \"Snowstorm/22018/1/PMTfied_1.parquet\"\n",
    "\n",
    "truth_11_2 = PMTfied_dir + \"Snowstorm/22011/truth_2.parquet\"\n",
    "\n",
    "truth_14_1 = PMTfied_dir + \"Snowstorm/22014/truth_1.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_root = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/PMTfied/\"\n",
    "dest_root = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/PMTfied_filtered/\"\n",
    "snowstorm_source_dir = source_root + \"Snowstorm/\"\n",
    "snowstorm_dest_dir = dest_root + \"Snowstorm/\"\n",
    "\n",
    "corsika_source_dir = source_root + \"Corsika/\"\n",
    "corsika_dest_dir = dest_root + \"Corsika/\"\n",
    "dir_99999 = snowstorm_dest_dir + \"99999/\"\n",
    "dir_99999_98 = dir_99999 + \"98/\"\n",
    "dir_99999_99 = dir_99999 + \"99/\"\n",
    "\n",
    "dir_99999_Corsika = corsika_dest_dir+\"9999999-9999999/\"\n",
    "dir_99999_Corsika_96 = dir_99999_Corsika + \"96/\"\n",
    "dir_99999_Corsika_97 = dir_99999_Corsika + \"97/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_nu_specifier_dir = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/clean_events_dict/\"\n",
    "pure_nu_specifier_18_1 = pure_nu_specifier_dir + \"2018/22018/clean_event_ids_0000000-0000999.csv\"\n",
    "pure_nu_specifier_11_1 = pure_nu_specifier_dir + \"2011/22011/clean_event_ids_0000000-0000999.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanniFile_22010_1 = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/clean_events_dict/22010/22010/clean_event_ids_0000000-0000999.csv\"\n",
    "JanniFile_22011_1 = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/clean_events_dict/22011/22011/clean_event_ids_0000000-0000999.csv\"\n",
    "JanniFile_22010_1_reduction = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/clean_events_dict/22010/22010/reduced/clean_event_ids_0000000-0000999.csv\"\n",
    "JanniFile_22011_1_reduction = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/clean_events_dict/22011/22011/reduced/clean_event_ids_0000000-0000999.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Subrun ID</th>\n",
       "      <th>Event ID</th>\n",
       "      <th>Subevent ID</th>\n",
       "      <th>Subevent Stream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>NullSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>InIceSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>NullSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>InIceSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>NullSplit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Run ID   Subrun ID  Event ID  Subevent ID Subevent Stream\n",
       "0  2201000093  4294967295        13            0       NullSplit\n",
       "1  2201000093  4294967295        13            0      InIceSplit\n",
       "2  2201000093  4294967295        49            0       NullSplit\n",
       "3  2201000093  4294967295        49            0      InIceSplit\n",
       "4  2201000093  4294967295        52            0       NullSplit"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_JanniFile_22010_1 = pd.read_csv(JanniFile_22010_1)\n",
    "df_JanniFile_22010_1.head()\n",
    "# 25sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Subrun ID</th>\n",
       "      <th>Event ID</th>\n",
       "      <th>Subevent ID</th>\n",
       "      <th>Subevent Stream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>4294967295</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Run ID   Subrun ID  Event ID  Subevent ID  Subevent Stream\n",
       "0  2201100000  4294967295        10            0              NaN\n",
       "1  2201100000  4294967295        23            0              NaN\n",
       "2  2201100000  4294967295        29            0              NaN\n",
       "3  2201100000  4294967295        40            0              NaN\n",
       "4  2201100000  4294967295        45            0              NaN"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_JanniFile_22011_1 = pd.read_csv(JanniFile_22011_1)\n",
    "df_JanniFile_22011_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunID</th>\n",
       "      <th>EventID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2201000093</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RunID  EventID\n",
       "0  2201000093       13\n",
       "1  2201000093       49\n",
       "2  2201000093       52\n",
       "3  2201000093       57\n",
       "4  2201000093       61"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_JanniFile_22010_1_reduction = pd.read_csv(JanniFile_22010_1_reduction)\n",
    "df_JanniFile_22010_1_reduction.head()\n",
    "# 6sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunID</th>\n",
       "      <th>EventID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2201100000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RunID  EventID\n",
       "0  2201100000       10\n",
       "1  2201100000       23\n",
       "2  2201100000       29\n",
       "3  2201100000       40\n",
       "4  2201100000       45"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_JanniFile_22011_1_reduction = pd.read_csv(JanniFile_22011_1_reduction)\n",
    "df_JanniFile_22011_1_reduction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dir = \"/lustre/hpc/project/icecube/HE_Nu_Aske_Oct2024/PMTfied_filtered/\"\n",
    "selected_events_dir = filtered_dir + \"PureNeutrinos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertParquetToDF(file:str) -> pd.DataFrame:\n",
    "    table = pq.read_table(file)\n",
    "    df = table.to_pandas()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth_18_1 = convertParquetToDF(truth_18_1)\n",
    "df_truth_11_2 = convertParquetToDF(truth_11_2)\n",
    "df_truth_14_1 = convertParquetToDF(truth_14_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_no', 'original_event_no', 'subdirectory_no', 'part_no',\n",
       "       'shard_no', 'N_doms', 'offset', 'energy', 'azimuth', 'zenith', 'pid',\n",
       "       'event_time', 'interaction_type', 'elasticity', 'RunID', 'SubrunID',\n",
       "       'EventID', 'SubEventID', 'dbang_decay_length', 'track_length',\n",
       "       'stopped_muon', 'energy_track', 'energy_cascade', 'inelasticity',\n",
       "       'DeepCoreFilter_13', 'CascadeFilter_13', 'MuonFilter_13',\n",
       "       'OnlineL2Filter_17', 'L3_oscNext_bool', 'L4_oscNext_bool',\n",
       "       'L5_oscNext_bool', 'L6_oscNext_bool', 'L7_oscNext_bool',\n",
       "       'Homogenized_QTot', 'MCLabelClassification', 'MCLabelCoincidentMuons',\n",
       "       'MCLabelBgMuonMCPE', 'MCLabelBgMuonMCPECharge',\n",
       "       'GNLabelTrackEnergyDeposited', 'GNLabelTrackEnergyOnEntrance',\n",
       "       'GNLabelTrackEnergyOnEntrancePrimary',\n",
       "       'GNLabelTrackEnergyDepositedPrimary', 'GNLabelEnergyPrimary',\n",
       "       'GNLabelCascadeEnergyDepositedPrimary', 'GNLabelCascadeEnergyDeposited',\n",
       "       'GNLabelEnergyDepositedTotal', 'GNLabelEnergyDepositedPrimary',\n",
       "       'GNLabelHighestEInIceParticleIsChild',\n",
       "       'GNLabelHighestEInIceParticleDistance',\n",
       "       'GNLabelHighestEInIceParticleEFraction',\n",
       "       'GNLabelHighestEDaughterDistance', 'GNLabelHighestEDaughterEFraction',\n",
       "       'zenith_GNHighestEInIceParticle', 'azimuth_GNHighestEInIceParticle',\n",
       "       'dir_x_GNHighestEInIceParticle', 'dir_y_GNHighestEInIceParticle',\n",
       "       'dir_z_GNHighestEInIceParticle', 'pos_x_GNHighestEInIceParticle',\n",
       "       'pos_y_GNHighestEInIceParticle', 'pos_z_GNHighestEInIceParticle',\n",
       "       'time_GNHighestEInIceParticle', 'speed_GNHighestEInIceParticle',\n",
       "       'energy_GNHighestEInIceParticle', 'zenith_GNHighestEDaughter',\n",
       "       'azimuth_GNHighestEDaughter', 'dir_x_GNHighestEDaughter',\n",
       "       'dir_y_GNHighestEDaughter', 'dir_z_GNHighestEDaughter',\n",
       "       'pos_x_GNHighestEDaughter', 'pos_y_GNHighestEDaughter',\n",
       "       'pos_z_GNHighestEDaughter', 'time_GNHighestEDaughter',\n",
       "       'speed_GNHighestEDaughter', 'energy_GNHighestEDaughter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth_11_2.columns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         111000200400561\n",
       "1         111000200400562\n",
       "2         111000200400563\n",
       "3         111000200400564\n",
       "4         111000200400565\n",
       "               ...       \n",
       "402680    111000200803241\n",
       "402681    111000200803242\n",
       "402682    111000200803243\n",
       "402683    111000200803244\n",
       "402684    111000200803245\n",
       "Name: event_no, Length: 402685, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth_11_2['event_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2201100014, 2201100015, 2201100016, 2201100017, 2201100018,\n",
       "       2201100019, 2201100020, 2201100024, 2201100045, 2201100049,\n",
       "       2201100050, 2201100054, 2201100055, 2201100056, 2201100057,\n",
       "       2201100058, 2201100084, 2201100085, 2201100086, 2201100087,\n",
       "       2201100088, 2201100089, 2201100090, 2201100094, 2201100095,\n",
       "       2201100096, 2201100097, 2201100098, 2201100099, 2201100100,\n",
       "       2201100104, 2201100105, 2201100118, 2201100139, 2201100140,\n",
       "       2201100144, 2201100145, 2201100146, 2201100147, 2201100148,\n",
       "       2201100149, 2201100150, 2201100154, 2201100155, 2201100156,\n",
       "       2201100157, 2201100159, 2201100160, 2201100196, 2201100197,\n",
       "       2201100198, 2201100199, 2201100200, 2201100204, 2201100205,\n",
       "       2201100206, 2201100207, 2201100208, 2201100209, 2201100210,\n",
       "       2201100214, 2201100215, 2201100216, 2201100217, 2201100218,\n",
       "       2201100219, 2201100220, 2201100254, 2201100255, 2201100256,\n",
       "       2201100257, 2201100258, 2201100259, 2201100260, 2201100264,\n",
       "       2201100265, 2201100266, 2201100268, 2201100269, 2201100270,\n",
       "       2201100274, 2201100275, 2201100276, 2201100277, 2201100278,\n",
       "       2201100310, 2201100314, 2201100315, 2201100316, 2201100317,\n",
       "       2201100318, 2201100319, 2201100320, 2201100324, 2201100325,\n",
       "       2201100326, 2201100327, 2201100328, 2201100330, 2201100334,\n",
       "       2201100367, 2201100368, 2201100370, 2201100374, 2201100375,\n",
       "       2201100376, 2201100377, 2201100378, 2201100379, 2201100380,\n",
       "       2201100384, 2201100385, 2201100386, 2201100387, 2201100388,\n",
       "       2201100389, 2201100390, 2201100409, 2201100424, 2201100425,\n",
       "       2201100426, 2201100427, 2201100428, 2201100429, 2201100430,\n",
       "       2201100434, 2201100435, 2201100436, 2201100437, 2201100438,\n",
       "       2201100439, 2201100440, 2201100444, 2201100445, 2201100446,\n",
       "       2201100447, 2201100448, 2201100484, 2201100485, 2201100487,\n",
       "       2201100488, 2201100489, 2201100490, 2201100494, 2201100495,\n",
       "       2201100496, 2201100497, 2201100498, 2201100499, 2201100500,\n",
       "       2201100518, 2201100519, 2201100520, 2201100524, 2201100525,\n",
       "       2201100527, 2201100528, 2201100529, 2201100534, 2201100554,\n",
       "       2201100555, 2201100556, 2201100557, 2201100558, 2201100559,\n",
       "       2201100560, 2201100580, 2201100584, 2201100585, 2201100586,\n",
       "       2201100587, 2201100588, 2201100589, 2201100590, 2201100600,\n",
       "       2201100614, 2201100615, 2201100616, 2201100617, 2201100618,\n",
       "       2201100619, 2201100620, 2201100624, 2201100644, 2201100645,\n",
       "       2201100646, 2201100647, 2201100648, 2201100649, 2201100650,\n",
       "       2201100675, 2201100676, 2201100677, 2201100678, 2201100680,\n",
       "       2201100684, 2201100685, 2201100686, 2201100687, 2201100704,\n",
       "       2201100705, 2201100706, 2201100707, 2201100708, 2201100710,\n",
       "       2201100714, 2201100715, 2201100738, 2201100739, 2201100740,\n",
       "       2201100744, 2201100745, 2201100746, 2201100747, 2201100748,\n",
       "       2201100749, 2201100766, 2201100767, 2201100768, 2201100769,\n",
       "       2201100770, 2201100774, 2201100775, 2201100776, 2201100777,\n",
       "       2201100794, 2201100795, 2201100796, 2201100797, 2201100798,\n",
       "       2201100799, 2201100800, 2201100804, 2201100805, 2201100806,\n",
       "       2201100807, 2201100808, 2201100809, 2201100810, 2201100828,\n",
       "       2201100829, 2201100834, 2201100835, 2201100836, 2201100837,\n",
       "       2201100838, 2201100839, 2201100856, 2201100857, 2201100858,\n",
       "       2201100859, 2201100860, 2201100864, 2201100865, 2201100866,\n",
       "       2201100867, 2201100868, 2201100869, 2201100870, 2201100890,\n",
       "       2201100894, 2201100895, 2201100896, 2201100897, 2201100898,\n",
       "       2201100899, 2201100900, 2201100909, 2201100918, 2201100919,\n",
       "       2201100920, 2201100924, 2201100925, 2201100926, 2201100927,\n",
       "       2201100928, 2201100929, 2201100930, 2201100934, 2201100935,\n",
       "       2201100944, 2201100954, 2201100955, 2201100956, 2201100957,\n",
       "       2201100958, 2201100959, 2201100960, 2201100965, 2201100994,\n",
       "       2201100995, 2201100996, 2201100997, 2201100998, 2201100999,\n",
       "       2201101000, 2201101004, 2201101005, 2201101006, 2201101007,\n",
       "       2201101008, 2201101026, 2201101027, 2201101028, 2201101029,\n",
       "       2201101030, 2201101035, 2201101036, 2201101037, 2201101038,\n",
       "       2201101039, 2201101046, 2201101047, 2201101048, 2201101059,\n",
       "       2201101060, 2201101064, 2201101065, 2201101066, 2201101067,\n",
       "       2201101068, 2201101069, 2201101070, 2201101074, 2201101075,\n",
       "       2201101104, 2201101108, 2201101109, 2201101110, 2201101114,\n",
       "       2201101115, 2201101116, 2201101117, 2201101118, 2201101119,\n",
       "       2201101120, 2201101124, 2201101125, 2201101126, 2201101127,\n",
       "       2201101128, 2201101129, 2201101130])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth_11_2['RunID'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunID       343\n",
       "EventID    8000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth_11_2[['RunID', 'EventID']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MuonFilter_13\n",
       "1    321550\n",
       "0     81135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth_11_2['MuonFilter_13'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventFilter(ABC):\n",
    "    @abstractmethod\n",
    "    def sort(self, pa_table: pa.Table) -> pa.Table:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuonFilter13(EventFilter):\n",
    "    def sort(self, pa_table: pa.Table) -> pa.Table:\n",
    "        return pa_table.filter(pa_table.column('MuonFilter_13') == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunIdEventIdFilter(EventFilter):\n",
    "    def __init__(self, file:str):\n",
    "        self.df = pd.read_csv(file).set_index(['RunID', 'EventID'])\n",
    "        \n",
    "    def sort(self, pa_table: pa.Table) -> pa.Table:\n",
    "        return pa_table.filter(pa_table.column('RunID').isin(self.df['RunID']) & pa_table.column('EventID').isin(self.df['EventID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_pure_neutrino_event_specifiers(pure_nu_specifier_dir:str,\n",
    "#                                         subdir_no:int):\n",
    "#     dir_path = os.path.join(pure_nu_specifier_dir, str(subdir_no), str(subdir_no), 'reduced')\n",
    "#     files = os.listdir(dir_path)\n",
    "#     print(len(files))\n",
    "#     print(files)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_pure_neutrino_event_specifiers(pure_nu_specifier_dir, 22018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_new_parquet(source_dir:str,\n",
    "#                     subdir_no: int, \n",
    "#                     part_no: int,\n",
    "#                     dest_dir:str,\n",
    "#                     sorting_hat: RunIdEventIdFilter,\n",
    "#                     ) -> None:\n",
    "#     source_truth_file = source_dir + str(subdir_no) + \"truth_\" + str(part_no) + \".parquet\"\n",
    "#     source_pmtfied_dir = source_dir + str(subdir_no) + \"/\" + str(part_no) + \"/\"\n",
    "#     source_pmtfied_files = os.listdir(source_pmtfied_dir)\n",
    "#     dest_pmtfied_dir = dest_dir + str(subdir_no) + \"/\" + str(part_no) + \"/\"\n",
    "#     print(f\"source_truth_file: {source_truth_file}\")\n",
    "#     if not os.path.exists(dest_pmtfied_dir):\n",
    "#         os.makedirs(dest_pmtfied_dir)\n",
    "#     for file in source_pmtfied_files:\n",
    "#         print(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_new_parquet(source_dir=snowstorm_source_dir,\n",
    "#                 subdir_no=22018, \n",
    "#                 part_no=1,\n",
    "#                 dest_dir=snowstorm_dest_dir,\n",
    "#                 sorting_hat=None,\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_specifier_files(csv_path: str) -> list:\n",
    "    files = os.listdir(csv_path)\n",
    "    \n",
    "    file_ranges = []\n",
    "    \n",
    "    for file in files:\n",
    "        if file.startswith(\"clean_event_ids_\") and file.endswith(\".csv\"):\n",
    "            groups = file.replace(\"clean_event_ids_\", \"\").replace(\".csv\", \"\").split(\"-\")\n",
    "            min_id, max_id = map(int, groups)\n",
    "            file_ranges.append((min_id, max_id, os.path.join(csv_path, file)))\n",
    "    file_ranges.sort(key=lambda x: x[0])\n",
    "\n",
    "    return file_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_csv_files(truth_table: pa.Table, \n",
    "                           file_ranges: list) -> list:\n",
    "    run_ids = truth_table.column(\"RunID\").to_pylist()\n",
    "    effective_run_ids = [rid % 100000 for rid in run_ids]\n",
    "\n",
    "    min_id, max_id = min(effective_run_ids), max(effective_run_ids)\n",
    "\n",
    "    # Select relevant files\n",
    "    return [file for file_min, file_max, file in file_ranges if file_min <= max_id and file_max >= min_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_event_ids_from_csvs(csv_files: list) -> set:\n",
    "    valid_events = set()\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        table = pc.read_csv(csv_file)\n",
    "        run_ids = table.column(\"RunID\").to_pylist()\n",
    "        event_ids = table.column(\"EventID\").to_pylist()\n",
    "\n",
    "        valid_events.update(zip(run_ids, event_ids))\n",
    "\n",
    "    return valid_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_no_range(pmt_file: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Get the minimum and maximum 'event_no' from a PMTfied parquet file.\n",
    "\n",
    "    Args:\n",
    "        pmt_file (str): Path to the PMTfied parquet file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (min_event_no, max_event_no)\n",
    "    \"\"\"\n",
    "    table = pq.read_table(pmt_file)\n",
    "    event_nos = table.column(\"event_no\")\n",
    "\n",
    "    if event_nos.num_rows == 0:\n",
    "        return None  # Empty file\n",
    "\n",
    "    min_event_no = pc.min(event_nos).as_py()\n",
    "    max_event_no = pc.max(event_nos).as_py()\n",
    "\n",
    "    return min_event_no, max_event_no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pmtfied_files(source_pmtfied_dir: str,\n",
    "                         dest_pmtfied_dir: str,\n",
    "                         valid_event_nos: set) -> None:\n",
    "    \"\"\"\n",
    "    Filter PMTfied files based on valid 'event_no' values from the truth file.\n",
    "\n",
    "    Args:\n",
    "        source_pmtfied_dir (str): Directory containing original PMTfied files.\n",
    "        dest_pmtfied_dir (str): Directory where filtered PMTfied files will be saved.\n",
    "        valid_event_nos (set): Set of valid 'event_no' values.\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_pmtfied_dir, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(source_pmtfied_dir):\n",
    "        source_pmtfied_file = os.path.join(source_pmtfied_dir, file)\n",
    "        dest_pmtfied_file = os.path.join(dest_pmtfied_dir, file)\n",
    "\n",
    "        # Query min/max 'event_no' for fast rejection\n",
    "        event_no_range = get_event_no_range(source_pmtfied_file)\n",
    "        if event_no_range is None:\n",
    "            print(f\"Skipping empty PMTfied file: {file}\")\n",
    "            continue\n",
    "        \n",
    "        min_event_no, max_event_no = event_no_range\n",
    "\n",
    "        # Quick rejection if there's no overlap\n",
    "        if min_event_no > max(valid_event_nos) or max_event_no < min(valid_event_nos):\n",
    "            print(f\"Skipping {file}: No overlap with valid event numbers.\")\n",
    "            continue\n",
    "\n",
    "        # Load PMTfied parquet file\n",
    "        pmt_table = pq.read_table(source_pmtfied_file)\n",
    "        pmt_event_nos = pmt_table.column(\"event_no\").to_pylist()\n",
    "\n",
    "        # Create filtering mask\n",
    "        valid_indices = [i for i, eno in enumerate(pmt_event_nos) if eno in valid_event_nos]\n",
    "\n",
    "        if valid_indices:\n",
    "            filtered_pmt_table = pmt_table.take(valid_indices)\n",
    "            pq.write_table(filtered_pmt_table, dest_pmtfied_file)\n",
    "            print(f\"Filtered PMTfied file saved to: {dest_pmtfied_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_truth_file(source_dir: str,\n",
    "                      subdir_no: int,\n",
    "                      part_no: int,\n",
    "                      pure_nu_specifier_dir: str,\n",
    "                      output_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Filter the truth file and corresponding PMTfied files based on event IDs.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): Base directory.\n",
    "        subdir_no (int): Subdirectory number.\n",
    "        part_no (int): Part number.\n",
    "        pure_nu_specifier_dir (str): Directory containing CSV event specifiers.\n",
    "        output_dir (str): Directory to store the filtered files.\n",
    "        file_ranges (list): Preloaded list of CSV files with min-max event ID ranges.\n",
    "    \"\"\"\n",
    "    csv_path = os.path.join(pure_nu_specifier_dir, str(subdir_no), str(subdir_no), 'reduced')\n",
    "    file_ranges = get_event_specifier_files(csv_path)\n",
    "    \n",
    "    source_truth_file = os.path.join(source_dir, str(subdir_no), f\"truth_{part_no}.parquet\")\n",
    "    truth_table = pq.read_table(source_truth_file)\n",
    "\n",
    "    # Get the relevant CSV files\n",
    "    relevant_csvs = get_relevant_csv_files(truth_table, file_ranges)\n",
    "\n",
    "    if not relevant_csvs:\n",
    "        print(f\"No matching CSV files found for {subdir_no}/{part_no}\")\n",
    "        return\n",
    "\n",
    "    # Load valid event (Run ID, Event ID) pairs\n",
    "    pure_neutrino_events = load_event_ids_from_csvs(relevant_csvs)\n",
    "\n",
    "    # Convert columns to lists once\n",
    "    run_ids = truth_table.column(\"RunID\").to_pylist()\n",
    "    event_ids = truth_table.column(\"EventID\").to_pylist()\n",
    "\n",
    "    # Create filtering mask\n",
    "    valid_indices = [i for i, (rid, eid) in enumerate(zip(run_ids, event_ids)) if (rid, eid) in pure_neutrino_events]\n",
    "\n",
    "    if not valid_indices:\n",
    "        print(f\"No valid events in {subdir_no}/{part_no}. Skipping truth file saving.\")\n",
    "        return\n",
    "\n",
    "    # Apply mask and extract valid event_no\n",
    "    filtered_truth_table = truth_table.take(valid_indices)\n",
    "    valid_event_nos = set(filtered_truth_table.column(\"event_no\").to_pylist())\n",
    "\n",
    "    output_truth_file = os.path.join(output_dir, str(subdir_no), f\"truth_{part_no}.parquet\")\n",
    "    os.makedirs(os.path.dirname(output_truth_file), exist_ok=True)\n",
    "    pq.write_table(filtered_truth_table, output_truth_file)\n",
    "\n",
    "    print(f\"Filtered truth file saved to: {output_truth_file}\")\n",
    "\n",
    "    # Now filter PMTfied files\n",
    "    source_pmtfied_dir = os.path.join(source_dir, str(subdir_no), str(part_no))\n",
    "    dest_pmtfied_dir = os.path.join(output_dir, str(subdir_no), str(part_no))\n",
    "    filter_pmtfied_files(source_pmtfied_dir, dest_pmtfied_dir, valid_event_nos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "CSV parse error: Expected 5 columns, got 3: 2201100000,10,",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfilter_truth_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnowstorm_source_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msubdir_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m22011\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpart_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpure_nu_specifier_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpure_nu_specifier_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnowstorm_dest_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 31\u001b[0m, in \u001b[0;36mfilter_truth_file\u001b[0;34m(source_dir, subdir_no, part_no, pure_nu_specifier_dir, output_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Load valid event (Run ID, Event ID) pairs\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m pure_neutrino_events \u001b[38;5;241m=\u001b[39m \u001b[43mload_event_ids_from_csvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelevant_csvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Convert columns to lists once\u001b[39;00m\n\u001b[1;32m     34\u001b[0m run_ids \u001b[38;5;241m=\u001b[39m truth_table\u001b[38;5;241m.\u001b[39mcolumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto_pylist()\n",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m, in \u001b[0;36mload_event_ids_from_csvs\u001b[0;34m(csv_files)\u001b[0m\n\u001b[1;32m      2\u001b[0m valid_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csv_file \u001b[38;5;129;01min\u001b[39;00m csv_files:\n\u001b[0;32m----> 5\u001b[0m     table \u001b[38;5;241m=\u001b[39m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     run_ids \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcolumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto_pylist()\n\u001b[1;32m      7\u001b[0m     event_ids \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcolumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto_pylist()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyarrow/_csv.pyx:1261\u001b[0m, in \u001b[0;36mpyarrow._csv.read_csv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyarrow/_csv.pyx:1270\u001b[0m, in \u001b[0;36mpyarrow._csv.read_csv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: CSV parse error: Expected 5 columns, got 3: 2201100000,10,"
     ]
    }
   ],
   "source": [
    "filter_truth_file(source_dir=snowstorm_source_dir,\n",
    "                    subdir_no=22011,\n",
    "                    part_no=1,\n",
    "                    pure_nu_specifier_dir=pure_nu_specifier_dir,\n",
    "                    output_dir=snowstorm_dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
